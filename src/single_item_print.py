single item:
{'img_id': ['COCO_train2014_000000552389'], 
 'instruction': ['\nProvide a one-sentence caption for the provided image.'], 
 'response': ['A dog with a hat on top of his head'], 
 'image': ['/media/data/ytllam/coco/train2014/COCO_train2014_000000552389.jpg'], 
 'targets': ["A dog with a hat on top of his head$$A small dog photographed very close to the camera.$$A light brown chihuahua dog wearing a fluffy hat$$An adorable small brown chihuahua wearing a white hat.$$The small dog is wearing a santa's hat for the picture."],
 'text': ['\nProvide a one-sentence caption for the provided image.'], 
 'model_output': tensor([[...]], device='cuda:0'), 
  'model_generated_output': tensor([[ ... ]], device='cuda:0'), 
  'model_predictions': ['A dog wearing a Santa hat and green eyes.']}
single item hook_data:
{'img_id': [['COCO_train2014_000000209139'], ['COCO_train2014_000000302661']], 
 'instruction': [['\nProvide a one-sentence caption for the provided image.'], ['\nProvide a one-sentence caption for the provided image.']], 
 'response': [['A dog in a pool swimming with a frisbee in its mouth.'], ['a few sheep are outside in a field with a dog']], 
 'image': [['/media/data/ytllam/coco/train2014/COCO_train2014_000000209139.jpg'], ['/media/data/ytllam/coco/train2014/COCO_train2014_000000302661.jpg']], 
 'targets': [['A dog in a pool swimming with a frisbee in its mouth.$$A dog in a pool with some sort of white ring in its mouth.$$a dog swimming in a pool holding a circular thing$$A dog catches a disc in its mouth while swimming.$$a dog in the water with a frisbee in its mouth'], ['a few sheep are outside in a field with a dog$$Sheep stand in a field while some drink water.$$A few sheep wander around and drink water$$Sheep eat from a blue bowl with the sheepdog behind them.$$two large sheep are and a dog and one of the sheep is eating out of a bowl.']], 
 'text': [['\nProvide a one-sentence caption for the provided image.'], ['\nProvide a one-sentence caption for the provided image.']], 
 'model_output': [tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 29871,    13,    13,  1184, 29894,   680,   263,   697, 29899,
         18616,   663,  5777,   683,   363,   278,  4944,  1967, 29889,   319,
          1799,  9047, 13566, 29901,   319, 11203,   338,  2381, 25217,   297,
           263, 11565,   411,   263,  1424,   275,   915, 29872,   297,   967,
         13394, 29889,     2]], device='cuda:0'), tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 29871,    13,    13,  1184, 29894,   680,   263,   697, 29899,
         18616,   663,  5777,   683,   363,   278,  4944,  1967, 29889,   319,
          1799,  9047, 13566, 29901,   319, 11203,   322,   263, 29735,   526,
         13748,   292,   515,   263, 12580, 29880, 29889,     2]],
       device='cuda:0')], 
  'model_generated_output': [
    tensor([[  319, 11203,   338,  2381, 25217,   297,   263, 11565,   411,   263,
          1424,   275,   915, 29872,   297,   967, 13394, 29889,     2]], device='cuda:0'),
    tensor([[  319, 11203,   322,   263, 29735,   526, 13748,   292,   515,   263,
          12580, 29880, 29889,     2]], device='cuda:0')],
  'model_predictions': [['A dog is swimming in a pool with a frisbee in its mouth.'], ['A dog and a sheep are drinking from a bowl.']],
  'token_of_interest_mask': [tensor([True], device='cuda:0'), tensor([True], device='cuda:0')], 
  'hidden_states': [
    {
      'language_model.model.layers.30': tensor([[[ 0.2061,  0.6006,  3.9609,  ..., -1.1494,  0.0562,  1.7207]]], dtype=torch.float16), 
      'language_model.model.layers.31': tensor([[[-0.3931, -2.3242,  4.4414,  ...,  0.1416,  1.3965,  1.2246]]], dtype=torch.float16),
      'language_model.model.norm': tensor([[[-0.2130, -1.2598,  2.3262,  ...,  0.0707,  0.7407,  0.5693]]], dtype=torch.float16)
    }, 
    {
      'language_model.model.layers.30': tensor([[[-0.3293, -0.3101,  4.3867,  ..., -1.9502, -1.3408, -1.2979]]], dtype=torch.float16),
      'language_model.model.layers.31': tensor([[[ 0.0090, -2.1270,  3.9004,  ..., -0.9541,  1.4922, -2.5195]]], dtype=torch.float16),
      'language_model.model.norm': tensor([[[ 0.0045, -1.0557,  1.8721,  ..., -0.4360,  0.7251, -1.0732]]], dtype=torch.float16)
    }
  ]}

item
{'img_id': ['COCO_train2014_000000209139'], 
 'instruction': ['\nProvide a one-sentence caption for the provided image.'], 
 'response': ['A dog in a pool swimming with a frisbee in its mouth.'], 
 'image': ['/media/data/ytllam/coco/train2014/COCO_train2014_000000209139.jpg'], 
 'targets': ['A dog in a pool swimming with a frisbee in its mouth.$$A dog in a pool with some sort of white ring in its mouth.$$a dog swimming in a pool holding a circular thing$$A dog catches a disc in its mouth while swimming.$$a dog in the water with a frisbee in its mouth'], 
 'text': ['\nProvide a one-sentence caption for the provided image.']}


 single item:
{'img_id': ['COCO_train2014_000000209139'], 
 'instruction': ['\nProvide a one-sentence caption for the provided image.'], 
 'response': ['A dog in a pool swimming with a frisbee in its mouth.'], 
 'image': ['/media/data/ytllam/coco/train2014/COCO_train2014_000000209139.jpg'], 
 'targets': ['A dog in a pool swimming with a frisbee in its mouth.$$A dog in a pool with some sort of white ring in its mouth.$$a dog swimming in a pool holding a circular thing$$A dog catches a disc in its mouth while swimming.$$a dog in the water with a frisbee in its mouth'],
 'text': ['\nProvide a one-sentence caption for the provided image.'], 
 'model_output': tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 29871,    13,    13,  1184, 29894,   680,   263,   697, 29899,
         18616,   663,  5777,   683,   363,   278,  4944,  1967, 29889,   319,
          1799,  9047, 13566, 29901,   319, 11203,   338,  2381, 25217,   297,
           263, 11565,   411,   263,  1424,   275,   915, 29872,   297,   967,
         13394, 29889,     2]], device='cuda:0'), 
  'model_generated_output': tensor([[  319, 11203,   338,  2381, 25217,   297,   263, 11565,   411,   263,
          1424,   275,   915, 29872,   297,   967, 13394, 29889,     2]],
       device='cuda:0'), 
  'model_predictions': ['A dog is swimming in a pool with a frisbee in its mouth.']}


single item hook_data:
{'img_id': [['COCO_train2014_000000209139']], 
 'instruction': [['\nProvide a one-sentence caption for the provided image.']], 
 'response': [['A dog in a pool swimming with a frisbee in its mouth.']], 
 'image': [['/media/data/ytllam/coco/train2014/COCO_train2014_000000209139.jpg']], 
 'targets': [['A dog in a pool swimming with a frisbee in its mouth.$$A dog in a pool with some sort of white ring in its mouth.$$a dog swimming in a pool holding a circular thing$$A dog catches a disc in its mouth while swimming.$$a dog in the water with a frisbee in its mouth']], 
 'text': [['\nProvide a one-sentence caption for the provided image.']], 
 'model_output': [tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 29871,    13,    13,  1184, 29894,   680,   263,   697, 29899,
         18616,   663,  5777,   683,   363,   278,  4944,  1967, 29889,   319,
          1799,  9047, 13566, 29901,   319, 11203,   338,  2381, 25217,   297,
           263, 11565,   411,   263,  1424,   275,   915, 29872,   297,   967,
         13394, 29889,     2]], device='cuda:0')], 
  'model_generated_output': [tensor([[  319, 11203,   338,  2381, 25217,   297,   263, 11565,   411,   263,
          1424,   275,   915, 29872,   297,   967, 13394, 29889,     2]],
       device='cuda:0')], 
  'model_predictions': [['A dog is swimming in a pool with a frisbee in its mouth.']], 
  'token_of_interest_mask': [tensor([True], device='cuda:0')], 
  'hidden_states': [{
    'language_model.model.layers.30': tensor([[[ 0.2061,  0.6006,  3.9609,  ..., -1.1494,  0.0562,  1.7207]]], dtype=torch.float16),
    'language_model.model.layers.31': tensor([[[-0.3931, -2.3242,  4.4414,  ...,  0.1416,  1.3965,  1.2246]]], dtype=torch.float16),
    'language_model.model.norm': tensor([[[-0.2130, -1.2598,  2.3262,  ...,  0.0707,  0.7407,  0.5693]]], dtype=torch.float16)
  }]
}




[{'language_model.model.layers.30': tensor([[[-1.5410,  0.7334,  0.0137,  ...,  0.6279, -1.4707,  0.3357]]], dtype=torch.float16), 
  'language_model.model.layers.31': tensor([[[-1.4170, -0.3098, -0.9253,  ...,  2.3809,  1.1504, -1.6709]]], dtype=torch.float16), 
  'language_model.model.norm': tensor([[[-0.7412, -0.1621, -0.4680,  ...,  1.1465,  0.5894, -0.7500]]], dtype=torch.float16)
  }, 
  {'language_model.model.layers.30': tensor([[[ 1.5684, -0.3230,  0.6997,  ..., -3.5859,  1.7412,  1.5645]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 3.4395, -1.9521,  2.7480,  ..., -3.1777,  4.0352, -0.4258]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.5371, -0.8726,  1.1865,  ..., -1.3076,  1.7656, -0.1632]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.6875, -0.1841,  3.1680,  ..., -2.9062,  2.3887,  1.6211]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 3.8945, -1.7588,  5.8281,  ..., -3.0273,  4.0781, -0.7979]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.7959, -0.8110,  2.5977,  ..., -1.2852,  1.8408, -0.3154]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.7832,  0.4351,  3.6719,  ...,  1.2012,  0.7119,  1.6182]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.3574, -1.4512,  3.4473,  ...,  2.7773,  2.1328,  1.0547]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.2549, -0.7725,  1.7734,  ...,  1.3613,  1.1113,  0.4817]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.4827, -3.0234,  3.9512,  ..., -2.7480,  1.1953, -2.8105]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.4258, -4.9609,  4.7695,  ..., -1.1611,  2.1875, -3.7598]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.6279, -2.1836,  2.0293,  ..., -0.4705,  0.9424, -1.4189]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.8599, -1.4570,  4.4531,  ..., -0.5137,  0.7793,  0.3896]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.0684, -1.5166,  4.1016,  ..., -0.8354,  3.7500, -0.0591]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.4910, -0.6968,  1.8223,  ..., -0.3533,  1.6875, -0.0233]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.4912, -2.9414,  4.2422,  ..., -3.2930,  0.6636, -2.6211]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.6045, -4.9570,  5.3906,  ..., -1.7939,  1.2881, -3.4004]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.2551, -2.0918,  2.1992,  ..., -0.6968,  0.5322, -1.2305]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.1113, -2.3105,  1.7344,  ..., -0.2373,  1.2139,  2.9922]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.9453, -3.9766,  1.3867,  ...,  1.6133,  2.7520,  2.6680]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.0020, -2.0469,  0.6904,  ...,  0.7651,  1.3877,  1.1787]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-3.1562, -0.1033,  0.2949,  ..., -1.0020,  1.2754,  3.3008]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-3.5312, -1.2822, -0.8486,  ...,  0.1797,  3.2871,  2.9590]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.6367, -0.5942, -0.3801,  ...,  0.0767,  1.4912,  1.1758]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.4736, -0.3806,  2.5156,  ...,  2.8262, -1.0078,  1.2598]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.6055, -2.2637,  2.5664,  ...,  4.5898,  0.6982,  0.6914]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.3313, -1.2383,  1.3574,  ...,  2.3105,  0.3738,  0.3242]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.5215, -3.2910,  3.0469,  ..., -1.3867, -1.3174,  1.7920]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.4414, -4.7734,  2.9473,  ...,  0.7100,  0.1650,  0.7686]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.1504, -2.2500,  1.3418,  ...,  0.3081,  0.0762,  0.3105]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.2284,  0.5537,  2.4570,  ...,  0.9258,  0.9307,  0.0389]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.1808, -1.0527,  2.6016,  ...,  2.2324,  3.3418, -0.2898]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.0997, -0.5806,  1.3867,  ...,  1.1338,  1.8047, -0.1371]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 1.3984, -0.5015,  1.6836,  ..., -3.9668,  0.6206,  2.2734]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.2090, -1.1260,  1.8330,  ..., -3.0020,  2.8438,  0.4697]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.5884, -0.5483,  0.8628,  ..., -1.3457,  1.3555,  0.1962]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.5469, -3.6406,  3.6328,  ..., -3.0410,  0.2661, -2.2637]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.3262, -5.7500,  3.9551,  ..., -1.3193,  1.5020, -3.1133]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.5801, -2.5137,  1.6729,  ..., -0.5312,  0.6431, -1.1680]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.1289, -2.4180,  2.6016,  ..., -1.7480, -0.4146,  1.1924]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.9199, -4.1484,  2.8105,  ...,  0.6055,  1.2832,  0.1436]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.8911, -1.9258,  1.2607,  ...,  0.2588,  0.5835,  0.0572]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.7827, -1.1934, -0.1562,  ..., -2.6055,  2.4277,  0.8149]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 3.0312, -1.4580,  1.3906,  ..., -2.8848,  3.6445, -1.0273]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.4053, -0.6763,  0.6230,  ..., -1.2314,  1.6543, -0.4087]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.8418, -2.3652,  2.5762,  ..., -1.2939, -2.4590,  0.4297]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.7852, -3.7734,  3.0566,  ...,  0.8076, -0.5693, -0.8105]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.2354, -1.6738,  1.3115,  ...,  0.3298, -0.2473, -0.3086]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.7568, -1.6191,  1.9072,  ..., -1.8096, -2.3125,  1.4424]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.0527, -3.1035,  1.9873,  ...,  0.1660, -0.5029,  0.7793]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.4927, -1.4521,  0.8989,  ...,  0.0715, -0.2305,  0.3127]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.5283,  0.7832,  3.7227,  ...,  1.7510,  0.0225,  0.2681]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-0.0205, -2.5449,  5.0547,  ...,  2.4180,  2.1680, -0.3198]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.0103, -1.2832,  2.4629,  ...,  1.1221,  1.0703, -0.1383]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.6328, -0.5088,  4.2109,  ...,  0.1416, -0.0217,  0.7363]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.2163, -2.9023,  5.0820,  ...,  0.2061,  1.2480, -0.4136]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.1082, -1.4512,  2.4570,  ...,  0.0949,  0.6108, -0.1774]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.3198, -2.5195, -0.7686,  ..., -2.2930, -1.2627,  0.7759]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.7969, -1.0996, -1.4805,  ..., -2.2832, -0.2898, -0.6821]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.3594, -0.4961, -0.6455,  ..., -0.9482, -0.1279, -0.2639]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.4043, -1.9043,  1.0967,  ..., -3.1777,  0.3154,  1.7764]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.3379, -4.2070,  1.4766,  ..., -0.9590,  2.8262,  0.5674]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.1650, -2.0977,  0.7109,  ..., -0.4397,  1.3789,  0.2424]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.0814,  1.8320,  0.8213,  ...,  1.9395,  3.0410,  0.0884]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.0696, -0.0312,  1.5996,  ...,  3.2344,  6.4961, -0.8418]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.0356, -0.0160,  0.7900,  ...,  1.5215,  3.2500, -0.3689]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.7847, -0.9277,  5.0195,  ..., -1.0615,  0.2065,  0.4805]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.8086, -3.9023,  4.8867,  ..., -0.1953,  2.0078, -2.0059]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.3894, -1.8799,  2.2734,  ..., -0.0865,  0.9463, -0.8281]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.9990, -2.0332,  4.2422,  ..., -2.8945,  1.0166, -2.8301]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.8706, -3.4609,  4.8438,  ..., -1.3408,  2.0820, -4.0078]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.4165, -1.6553,  2.2402,  ..., -0.5903,  0.9746, -1.6436]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.8457, -0.1675,  2.6602,  ...,  1.0049,  0.8086,  1.2344]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.3584, -1.1582,  2.2949,  ...,  3.2832,  2.2656, -0.3594]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.6138, -0.5234,  1.0020,  ...,  1.3652,  1.0020, -0.1392]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.9121, -2.8145,  3.8574,  ..., -1.0693, -1.4844,  0.6968]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-3.1914, -5.3203,  4.3086,  ...,  0.1699,  0.0430, -0.2446]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.4883, -2.4805,  1.9404,  ...,  0.0729,  0.0196, -0.0978]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 1.6484,  1.1318,  4.6406,  ..., -0.9497,  0.1475,  3.6230]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 3.1113,  1.4893,  6.2578,  ..., -0.3315,  0.8604,  2.6797]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.4424,  0.6899,  2.8047,  ..., -0.1414,  0.3906,  1.0654]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.8281, -2.3379, -0.0605,  ...,  0.4854,  0.1140,  0.4463]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-0.4441, -3.5098, -0.3408,  ...,  2.2852,  0.8960, -0.6143]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.2634, -2.0820, -0.1956,  ...,  1.2480,  0.5205, -0.3125]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.5332, -3.3477,  4.8477,  ..., -3.6602,  0.4370, -2.1738]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.9814, -5.7891,  5.7461,  ..., -2.2109,  0.9580, -3.1133]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.8027, -2.3457,  2.2500,  ..., -0.8247,  0.3801, -1.0811]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.8203, -0.9570,  1.9375,  ..., -0.9014, -0.9243, -0.6709]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-0.2949, -2.2734,  2.0078,  ...,  0.9102, -0.1509, -2.1445]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.1338, -1.0312,  0.8804,  ...,  0.3801, -0.0670, -0.8345]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 2.6055, -0.7959,  2.1309,  ..., -0.9004,  2.1582,  0.6519]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 5.3906, -1.4219,  3.6992,  ..., -1.4053,  3.2656, -1.1816]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 2.2734, -0.6001,  1.5078,  ..., -0.5454,  1.3486, -0.4275]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.3486,  0.4004,  3.8926,  ...,  0.0823, -1.3330,  2.3887]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-0.4858, -2.1680,  3.6035,  ...,  1.6367,  0.4082,  0.9707]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.2240, -1.0000,  1.6064,  ...,  0.6948,  0.1843,  0.3840]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-0.7334, -1.8564,  3.0410,  ..., -3.5078,  0.7700, -1.2246]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.3418, -3.3418,  2.9102,  ..., -1.6387,  1.3125, -2.6074]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.6348, -1.5801,  1.3301,  ..., -0.7134,  0.6079, -1.0576]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.9277, -0.6743,  2.1543,  ...,  0.2407,  1.1924,  2.2090]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.1152, -1.5801,  1.9541,  ...,  2.3984,  2.7207,  0.7305]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.0225, -0.7646,  0.9136,  ...,  1.0684,  1.2891,  0.3030]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.7402, -1.9316,  3.0059,  ..., -2.5527, -1.9697,  0.7573]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-3.3828e+00, -3.6797e+00,  3.3398e+00,  ..., -8.8086e-01,
           5.4785e-01, -1.9531e-03]]], dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.6309e+00, -1.7744e+00,  1.5566e+00,  ..., -3.9087e-01,
           2.5854e-01, -8.0776e-04]]], dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 1.5449, -1.5781,  3.2227,  ..., -1.9668,  0.6826, -0.2336]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 2.5820, -3.7578,  3.6934,  ..., -1.0391,  1.3789, -1.3271]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.2852, -1.8711,  1.7773,  ..., -0.4763,  0.6724, -0.5669]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 2.5410,  0.2893,  2.9727,  ..., -0.6489,  2.1953,  1.3086]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 6.2969, -0.5195,  3.6328,  ..., -1.2422,  3.3242,  0.4980]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 2.8965, -0.2391,  1.6152,  ..., -0.5264,  1.4971,  0.1965]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 1.9941,  1.3750,  1.8779,  ..., -1.7676,  2.0898,  0.6909]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 1.7500, -0.5605,  2.1719,  ..., -0.0645,  3.5156, -0.2041]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 1.0479, -0.3354,  1.2568,  ..., -0.0355,  2.0605, -0.1048]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-3.5352,  1.0840,  2.5664,  ..., -2.6250,  2.3027,  1.6738]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-3.5391, -0.7920,  3.1953,  ..., -0.6309,  3.8516,  1.2510]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.7305, -0.3872,  1.5098,  ..., -0.2839,  1.8438,  0.5249]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 3.3398, -0.1749,  1.5088,  ..., -2.4922,  3.6270, -0.1411]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 5.5781,  0.0886,  1.7207,  ..., -2.1309,  5.5859, -1.5801]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 2.5703,  0.0409,  0.7666,  ..., -0.9038,  2.5215, -0.6245]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 0.6113, -0.8813,  3.0781,  ..., -1.2744,  0.4570,  2.0293]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 0.4355, -3.2617,  4.0312,  ..., -0.1455,  2.7070,  0.4746]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 0.2373, -1.7773,  2.1211,  ..., -0.0729,  1.4434,  0.2217]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-2.0918, -0.4351, -2.4219,  ..., -2.4219, -1.6338,  0.6348]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-2.8848, -1.1855, -3.9258,  ..., -0.4043,  0.3135, -0.3101]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-1.3877, -0.5703, -1.8242,  ..., -0.1790,  0.1476, -0.1278]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[ 2.7266,  0.2384,  1.6826,  ..., -2.8516,  1.4980,  1.3887]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[ 4.9961, -0.5894,  3.7148,  ..., -3.4023,  3.0625, -1.0547]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[ 2.3438, -0.2764,  1.6836,  ..., -1.4688,  1.4062, -0.4243]]],
       dtype=torch.float16)}, {'language_model.model.layers.30': tensor([[[-1.7031, -1.3379,  1.5166,  ..., -3.2148,  1.8320,  0.3823]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.1660, -2.6250,  2.2617,  ..., -1.1523,  3.6523, -1.0645]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.6372, -1.4346,  1.1953,  ..., -0.5801,  1.9551, -0.4990]]],
       dtype=torch.float16)}]


{'language_model.model.layers.30': tensor([[[-1.5410,  0.7334,  0.0137,  ...,  0.6279, -1.4707,  0.3357]]], dtype=torch.float16), 
'language_model.model.layers.31': tensor([[[-1.4170, -0.3098, -0.9253,  ...,  2.3809,  1.1504, -1.6709]]], dtype=torch.float16), 
'language_model.model.norm': tensor([[[-0.7412, -0.1621, -0.4680,  ...,  1.1465,  0.5894, -0.7500]]], dtype=torch.float16)}


{'language_model.model.layers.30': [[[1]]], 
'language_model.model.layers.31': [[[1]]], 
'language_model.model.norm': [[[1]]]}


print_dict_structure_compact(d_single)
image -> list, len=45
image[0] -> list, len=1
image[0][0] -> str, len=65
image[1] -> list, len=1
image[1][0] -> str, len=65
image[2] -> list, len=1
image[2][0] -> str, len=65
image[3] -> list, len=1
image[3][0] -> str, len=65
image[4] -> list, len=1
image[4][0] -> str, len=65
image[5] -> list, len=1
image[5][0] -> str, len=65
image[6] -> list, len=1
image[6][0] -> str, len=65
image[7] -> list, len=1
image[7][0] -> str, len=65
image[8] -> list, len=1
image[8][0] -> str, len=65
image[9] -> list, len=1
image[9][0] -> str, len=65
image[10] -> list, len=1
image[10][0] -> str, len=65
image[11] -> list, len=1
image[11][0] -> str, len=65
image[12] -> list, len=1
image[12][0] -> str, len=65
image[13] -> list, len=1
image[13][0] -> str, len=65
image[14] -> list, len=1
image[14][0] -> str, len=65
image[15] -> list, len=1
image[15][0] -> str, len=65
image[16] -> list, len=1
image[16][0] -> str, len=65
image[17] -> list, len=1
image[17][0] -> str, len=65
image[18] -> list, len=1
image[18][0] -> str, len=65
image[19] -> list, len=1
image[19][0] -> str, len=65
image[20] -> list, len=1
image[20][0] -> str, len=65
image[21] -> list, len=1
image[21][0] -> str, len=65
image[22] -> list, len=1
image[22][0] -> str, len=65
image[23] -> list, len=1
image[23][0] -> str, len=65
image[24] -> list, len=1
image[24][0] -> str, len=65
image[25] -> list, len=1
image[25][0] -> str, len=65
image[26] -> list, len=1
image[26][0] -> str, len=65
image[27] -> list, len=1
image[27][0] -> str, len=65
image[28] -> list, len=1
image[28][0] -> str, len=65
image[29] -> list, len=1
image[29][0] -> str, len=65
image[30] -> list, len=1
image[30][0] -> str, len=65
image[31] -> list, len=1
image[31][0] -> str, len=65
image[32] -> list, len=1
image[32][0] -> str, len=65
image[33] -> list, len=1
image[33][0] -> str, len=65
image[34] -> list, len=1
image[34][0] -> str, len=65
image[35] -> list, len=1
image[35][0] -> str, len=65
image[36] -> list, len=1
image[36][0] -> str, len=65
image[37] -> list, len=1
image[37][0] -> str, len=65
image[38] -> list, len=1
image[38][0] -> str, len=65
image[39] -> list, len=1
image[39][0] -> str, len=65
image[40] -> list, len=1
image[40][0] -> str, len=65
image[41] -> list, len=1
image[41][0] -> str, len=65
image[42] -> list, len=1
image[42][0] -> str, len=65
image[43] -> list, len=1
image[43][0] -> str, len=65
image[44] -> list, len=1
image[44][0] -> str, len=65
model_predictions -> list, len=45
model_predictions[0] -> list, len=1
model_predictions[0][0] -> str, len=67
model_predictions[1] -> list, len=1
model_predictions[1][0] -> str, len=45
model_predictions[2] -> list, len=1
model_predictions[2][0] -> str, len=57
model_predictions[3] -> list, len=1
model_predictions[3][0] -> str, len=56
model_predictions[4] -> list, len=1
model_predictions[4][0] -> str, len=44
model_predictions[5] -> list, len=1
model_predictions[5][0] -> str, len=47
model_predictions[6] -> list, len=1
model_predictions[6][0] -> str, len=39
model_predictions[7] -> list, len=1
model_predictions[7][0] -> str, len=41
model_predictions[8] -> list, len=1
model_predictions[8][0] -> str, len=41
model_predictions[9] -> list, len=1
model_predictions[9][0] -> str, len=40
model_predictions[10] -> list, len=1
model_predictions[10][0] -> str, len=47
model_predictions[11] -> list, len=1
model_predictions[11][0] -> str, len=48
model_predictions[12] -> list, len=1
model_predictions[12][0] -> str, len=55
model_predictions[13] -> list, len=1
model_predictions[13][0] -> str, len=43
model_predictions[14] -> list, len=1
model_predictions[14][0] -> str, len=46
model_predictions[15] -> list, len=1
model_predictions[15][0] -> str, len=72
model_predictions[16] -> list, len=1
model_predictions[16][0] -> str, len=55
model_predictions[17] -> list, len=1
model_predictions[17][0] -> str, len=36
model_predictions[18] -> list, len=1
model_predictions[18][0] -> str, len=50
model_predictions[19] -> list, len=1
model_predictions[19][0] -> str, len=51
model_predictions[20] -> list, len=1
model_predictions[20][0] -> str, len=52
model_predictions[21] -> list, len=1
model_predictions[21][0] -> str, len=50
model_predictions[22] -> list, len=1
model_predictions[22][0] -> str, len=76
model_predictions[23] -> list, len=1
model_predictions[23][0] -> str, len=44
model_predictions[24] -> list, len=1
model_predictions[24][0] -> str, len=49
model_predictions[25] -> list, len=1
model_predictions[25][0] -> str, len=36
model_predictions[26] -> list, len=1
model_predictions[26][0] -> str, len=42
model_predictions[27] -> list, len=1
model_predictions[27][0] -> str, len=51
model_predictions[28] -> list, len=1
model_predictions[28][0] -> str, len=54
model_predictions[29] -> list, len=1
model_predictions[29][0] -> str, len=48
model_predictions[30] -> list, len=1
model_predictions[30][0] -> str, len=64
model_predictions[31] -> list, len=1
model_predictions[31][0] -> str, len=55
model_predictions[32] -> list, len=1
model_predictions[32][0] -> str, len=35
model_predictions[33] -> list, len=1
model_predictions[33][0] -> str, len=65
model_predictions[34] -> list, len=1
model_predictions[34][0] -> str, len=64
model_predictions[35] -> list, len=1
model_predictions[35][0] -> str, len=59
model_predictions[36] -> list, len=1
model_predictions[36][0] -> str, len=53
model_predictions[37] -> list, len=1
model_predictions[37][0] -> str, len=61
model_predictions[38] -> list, len=1
model_predictions[38][0] -> str, len=42
model_predictions[39] -> list, len=1
model_predictions[39][0] -> str, len=46
model_predictions[40] -> list, len=1
model_predictions[40][0] -> str, len=49
model_predictions[41] -> list, len=1
model_predictions[41][0] -> str, len=57
model_predictions[42] -> list, len=1
model_predictions[42][0] -> str, len=60
model_predictions[43] -> list, len=1
model_predictions[43][0] -> str, len=56
model_predictions[44] -> list, len=1
model_predictions[44][0] -> str, len=40
token_of_interest_mask -> list, len=45
token_of_interest_mask[0] -> Tensor, len=1
token_of_interest_mask[1] -> Tensor, len=1
token_of_interest_mask[2] -> Tensor, len=1
token_of_interest_mask[3] -> Tensor, len=1
token_of_interest_mask[4] -> Tensor, len=1
token_of_interest_mask[5] -> Tensor, len=1
token_of_interest_mask[6] -> Tensor, len=1
token_of_interest_mask[7] -> Tensor, len=1
token_of_interest_mask[8] -> Tensor, len=1
token_of_interest_mask[9] -> Tensor, len=1
token_of_interest_mask[10] -> Tensor, len=1
token_of_interest_mask[11] -> Tensor, len=1
token_of_interest_mask[12] -> Tensor, len=1
token_of_interest_mask[13] -> Tensor, len=1
token_of_interest_mask[14] -> Tensor, len=1
token_of_interest_mask[15] -> Tensor, len=1
token_of_interest_mask[16] -> Tensor, len=1
token_of_interest_mask[17] -> Tensor, len=1
token_of_interest_mask[18] -> Tensor, len=1
token_of_interest_mask[19] -> Tensor, len=1
token_of_interest_mask[20] -> Tensor, len=1
token_of_interest_mask[21] -> Tensor, len=1
token_of_interest_mask[22] -> Tensor, len=1
token_of_interest_mask[23] -> Tensor, len=1
token_of_interest_mask[24] -> Tensor, len=1
token_of_interest_mask[25] -> Tensor, len=1
token_of_interest_mask[26] -> Tensor, len=1
token_of_interest_mask[27] -> Tensor, len=1
token_of_interest_mask[28] -> Tensor, len=1
token_of_interest_mask[29] -> Tensor, len=1
token_of_interest_mask[30] -> Tensor, len=1
token_of_interest_mask[31] -> Tensor, len=1
token_of_interest_mask[32] -> Tensor, len=1
token_of_interest_mask[33] -> Tensor, len=1
token_of_interest_mask[34] -> Tensor, len=1
token_of_interest_mask[35] -> Tensor, len=1
token_of_interest_mask[36] -> Tensor, len=1
token_of_interest_mask[37] -> Tensor, len=1
token_of_interest_mask[38] -> Tensor, len=1
token_of_interest_mask[39] -> Tensor, len=1
token_of_interest_mask[40] -> Tensor, len=1
token_of_interest_mask[41] -> Tensor, len=1
token_of_interest_mask[42] -> Tensor, len=1
token_of_interest_mask[43] -> Tensor, len=1
token_of_interest_mask[44] -> Tensor, len=1
hidden_states -> list, len=45
hidden_states[0] -> dict, len=3
hidden_states[0].language_model.model.layers.30 -> Tensor, len=1
hidden_states[0].language_model.model.layers.31 -> Tensor, len=1
hidden_states[0].language_model.model.norm -> Tensor, len=1
hidden_states[1] -> dict, len=3
hidden_states[1].language_model.model.layers.30 -> Tensor, len=1
hidden_states[1].language_model.model.layers.31 -> Tensor, len=1
hidden_states[1].language_model.model.norm -> Tensor, len=1
hidden_states[2] -> dict, len=3
hidden_states[2].language_model.model.layers.30 -> Tensor, len=1
hidden_states[2].language_model.model.layers.31 -> Tensor, len=1
hidden_states[2].language_model.model.norm -> Tensor, len=1
hidden_states[3] -> dict, len=3
hidden_states[3].language_model.model.layers.30 -> Tensor, len=1
hidden_states[3].language_model.model.layers.31 -> Tensor, len=1
hidden_states[3].language_model.model.norm -> Tensor, len=1
hidden_states[4] -> dict, len=3
hidden_states[4].language_model.model.layers.30 -> Tensor, len=1
hidden_states[4].language_model.model.layers.31 -> Tensor, len=1
hidden_states[4].language_model.model.norm -> Tensor, len=1
hidden_states[5] -> dict, len=3
hidden_states[5].language_model.model.layers.30 -> Tensor, len=1
hidden_states[5].language_model.model.layers.31 -> Tensor, len=1
hidden_states[5].language_model.model.norm -> Tensor, len=1
hidden_states[6] -> dict, len=3
hidden_states[6].language_model.model.layers.30 -> Tensor, len=1
hidden_states[6].language_model.model.layers.31 -> Tensor, len=1
hidden_states[6].language_model.model.norm -> Tensor, len=1
hidden_states[7] -> dict, len=3
hidden_states[7].language_model.model.layers.30 -> Tensor, len=1
hidden_states[7].language_model.model.layers.31 -> Tensor, len=1
hidden_states[7].language_model.model.norm -> Tensor, len=1
hidden_states[8] -> dict, len=3
hidden_states[8].language_model.model.layers.30 -> Tensor, len=1
hidden_states[8].language_model.model.layers.31 -> Tensor, len=1
hidden_states[8].language_model.model.norm -> Tensor, len=1
hidden_states[9] -> dict, len=3
hidden_states[9].language_model.model.layers.30 -> Tensor, len=1
hidden_states[9].language_model.model.layers.31 -> Tensor, len=1
hidden_states[9].language_model.model.norm -> Tensor, len=1
hidden_states[10] -> dict, len=3
hidden_states[10].language_model.model.layers.30 -> Tensor, len=1
hidden_states[10].language_model.model.layers.31 -> Tensor, len=1
hidden_states[10].language_model.model.norm -> Tensor, len=1
hidden_states[11] -> dict, len=3
hidden_states[11].language_model.model.layers.30 -> Tensor, len=1
hidden_states[11].language_model.model.layers.31 -> Tensor, len=1
hidden_states[11].language_model.model.norm -> Tensor, len=1
hidden_states[12] -> dict, len=3
hidden_states[12].language_model.model.layers.30 -> Tensor, len=1
hidden_states[12].language_model.model.layers.31 -> Tensor, len=1
hidden_states[12].language_model.model.norm -> Tensor, len=1
hidden_states[13] -> dict, len=3
hidden_states[13].language_model.model.layers.30 -> Tensor, len=1
hidden_states[13].language_model.model.layers.31 -> Tensor, len=1
hidden_states[13].language_model.model.norm -> Tensor, len=1
hidden_states[14] -> dict, len=3
hidden_states[14].language_model.model.layers.30 -> Tensor, len=1
hidden_states[14].language_model.model.layers.31 -> Tensor, len=1
hidden_states[14].language_model.model.norm -> Tensor, len=1
hidden_states[15] -> dict, len=3
hidden_states[15].language_model.model.layers.30 -> Tensor, len=1
hidden_states[15].language_model.model.layers.31 -> Tensor, len=1
hidden_states[15].language_model.model.norm -> Tensor, len=1
hidden_states[16] -> dict, len=3
hidden_states[16].language_model.model.layers.30 -> Tensor, len=1
hidden_states[16].language_model.model.layers.31 -> Tensor, len=1
hidden_states[16].language_model.model.norm -> Tensor, len=1
hidden_states[17] -> dict, len=3
hidden_states[17].language_model.model.layers.30 -> Tensor, len=1
hidden_states[17].language_model.model.layers.31 -> Tensor, len=1
hidden_states[17].language_model.model.norm -> Tensor, len=1
hidden_states[18] -> dict, len=3
hidden_states[18].language_model.model.layers.30 -> Tensor, len=1
hidden_states[18].language_model.model.layers.31 -> Tensor, len=1
hidden_states[18].language_model.model.norm -> Tensor, len=1
hidden_states[19] -> dict, len=3
hidden_states[19].language_model.model.layers.30 -> Tensor, len=1
hidden_states[19].language_model.model.layers.31 -> Tensor, len=1
hidden_states[19].language_model.model.norm -> Tensor, len=1
hidden_states[20] -> dict, len=3
hidden_states[20].language_model.model.layers.30 -> Tensor, len=1
hidden_states[20].language_model.model.layers.31 -> Tensor, len=1
hidden_states[20].language_model.model.norm -> Tensor, len=1
hidden_states[21] -> dict, len=3
hidden_states[21].language_model.model.layers.30 -> Tensor, len=1
hidden_states[21].language_model.model.layers.31 -> Tensor, len=1
hidden_states[21].language_model.model.norm -> Tensor, len=1
hidden_states[22] -> dict, len=3
hidden_states[22].language_model.model.layers.30 -> Tensor, len=1
hidden_states[22].language_model.model.layers.31 -> Tensor, len=1
hidden_states[22].language_model.model.norm -> Tensor, len=1
hidden_states[23] -> dict, len=3
hidden_states[23].language_model.model.layers.30 -> Tensor, len=1
hidden_states[23].language_model.model.layers.31 -> Tensor, len=1
hidden_states[23].language_model.model.norm -> Tensor, len=1
hidden_states[24] -> dict, len=3
hidden_states[24].language_model.model.layers.30 -> Tensor, len=1
hidden_states[24].language_model.model.layers.31 -> Tensor, len=1
hidden_states[24].language_model.model.norm -> Tensor, len=1
hidden_states[25] -> dict, len=3
hidden_states[25].language_model.model.layers.30 -> Tensor, len=1
hidden_states[25].language_model.model.layers.31 -> Tensor, len=1
hidden_states[25].language_model.model.norm -> Tensor, len=1
hidden_states[26] -> dict, len=3
hidden_states[26].language_model.model.layers.30 -> Tensor, len=1
hidden_states[26].language_model.model.layers.31 -> Tensor, len=1
hidden_states[26].language_model.model.norm -> Tensor, len=1
hidden_states[27] -> dict, len=3
hidden_states[27].language_model.model.layers.30 -> Tensor, len=1
hidden_states[27].language_model.model.layers.31 -> Tensor, len=1
hidden_states[27].language_model.model.norm -> Tensor, len=1
hidden_states[28] -> dict, len=3
hidden_states[28].language_model.model.layers.30 -> Tensor, len=1
hidden_states[28].language_model.model.layers.31 -> Tensor, len=1
hidden_states[28].language_model.model.norm -> Tensor, len=1
hidden_states[29] -> dict, len=3
hidden_states[29].language_model.model.layers.30 -> Tensor, len=1
hidden_states[29].language_model.model.layers.31 -> Tensor, len=1
hidden_states[29].language_model.model.norm -> Tensor, len=1
hidden_states[30] -> dict, len=3
hidden_states[30].language_model.model.layers.30 -> Tensor, len=1
hidden_states[30].language_model.model.layers.31 -> Tensor, len=1
hidden_states[30].language_model.model.norm -> Tensor, len=1
hidden_states[31] -> dict, len=3
hidden_states[31].language_model.model.layers.30 -> Tensor, len=1
hidden_states[31].language_model.model.layers.31 -> Tensor, len=1
hidden_states[31].language_model.model.norm -> Tensor, len=1
hidden_states[32] -> dict, len=3
hidden_states[32].language_model.model.layers.30 -> Tensor, len=1
hidden_states[32].language_model.model.layers.31 -> Tensor, len=1
hidden_states[32].language_model.model.norm -> Tensor, len=1
hidden_states[33] -> dict, len=3
hidden_states[33].language_model.model.layers.30 -> Tensor, len=1
hidden_states[33].language_model.model.layers.31 -> Tensor, len=1
hidden_states[33].language_model.model.norm -> Tensor, len=1
hidden_states[34] -> dict, len=3
hidden_states[34].language_model.model.layers.30 -> Tensor, len=1
hidden_states[34].language_model.model.layers.31 -> Tensor, len=1
hidden_states[34].language_model.model.norm -> Tensor, len=1
hidden_states[35] -> dict, len=3
hidden_states[35].language_model.model.layers.30 -> Tensor, len=1
hidden_states[35].language_model.model.layers.31 -> Tensor, len=1
hidden_states[35].language_model.model.norm -> Tensor, len=1
hidden_states[36] -> dict, len=3
hidden_states[36].language_model.model.layers.30 -> Tensor, len=1
hidden_states[36].language_model.model.layers.31 -> Tensor, len=1
hidden_states[36].language_model.model.norm -> Tensor, len=1
hidden_states[37] -> dict, len=3
hidden_states[37].language_model.model.layers.30 -> Tensor, len=1
hidden_states[37].language_model.model.layers.31 -> Tensor, len=1
hidden_states[37].language_model.model.norm -> Tensor, len=1
hidden_states[38] -> dict, len=3
hidden_states[38].language_model.model.layers.30 -> Tensor, len=1
hidden_states[38].language_model.model.layers.31 -> Tensor, len=1
hidden_states[38].language_model.model.norm -> Tensor, len=1
hidden_states[39] -> dict, len=3
hidden_states[39].language_model.model.layers.30 -> Tensor, len=1
hidden_states[39].language_model.model.layers.31 -> Tensor, len=1
hidden_states[39].language_model.model.norm -> Tensor, len=1
hidden_states[40] -> dict, len=3
hidden_states[40].language_model.model.layers.30 -> Tensor, len=1
hidden_states[40].language_model.model.layers.31 -> Tensor, len=1
hidden_states[40].language_model.model.norm -> Tensor, len=1
hidden_states[41] -> dict, len=3
hidden_states[41].language_model.model.layers.30 -> Tensor, len=1
hidden_states[41].language_model.model.layers.31 -> Tensor, len=1
hidden_states[41].language_model.model.norm -> Tensor, len=1
hidden_states[42] -> dict, len=3
hidden_states[42].language_model.model.layers.30 -> Tensor, len=1
hidden_states[42].language_model.model.layers.31 -> Tensor, len=1
hidden_states[42].language_model.model.norm -> Tensor, len=1
hidden_states[43] -> dict, len=3
hidden_states[43].language_model.model.layers.30 -> Tensor, len=1
hidden_states[43].language_model.model.layers.31 -> Tensor, len=1
hidden_states[43].language_model.model.norm -> Tensor, len=1
hidden_states[44] -> dict, len=3
hidden_states[44].language_model.model.layers.30 -> Tensor, len=1
hidden_states[44].language_model.model.layers.31 -> Tensor, len=1
hidden_states[44].language_model.model.norm -> Tensor, len=1


is_batched=False, item:
{'img_id': ['COCO_train2014_000000006197'], 'instruction': ['\nProvide a one-sentence caption for the provided image.'], 'response': ['A dog standing by a truck pulling a trailer.'], 'image': ['/media/data/ytllam/coco/train2014/COCO_train2014_000000006197.jpg'], 'targets': ['A dog standing by a truck pulling a trailer.$$The dog as found by the pick up towing a trailer.$$A dog roaming the grounds in a campground area.$$A Dodge ram hauls a trailer with an ATV sitting in the truck bed.$$A dog stands in the foreground with a truck and camper in the background.'], 'text': ['\nProvide a one-sentence caption for the provided image.'], 'model_output': tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,
         32000, 29871,    13,    13,  1184, 29894,   680,   263,   697, 29899,
         18616,   663,  5777,   683,   363,   278,  4944,  1967, 29889,   319,
          1799,  9047, 13566, 29901,   319,  4796, 11203, 15028,   297,  4565,
           310,   263, 13283,   534,  2707,   322,   263, 13283,  1020,  3955,
         29889,     2]], device='cuda:0'), 'model_generated_output': tensor([[  319,  4796, 11203, 15028,   297,  4565,   310,   263, 13283,   534,
          2707,   322,   263, 13283,  1020,  3955, 29889,     2]],
       device='cuda:0'), 'model_predictions': ['A white dog stands in front of a silver truck and a silver trailer.'], 'token_of_interest_mask': tensor([True], device='cuda:0'), 'hidden_states': {'language_model.model.layers.30': tensor([[[-1.5410,  0.7334,  0.0137,  ...,  0.6279, -1.4707,  0.3357]]],
       dtype=torch.float16), 'language_model.model.layers.31': tensor([[[-1.4170, -0.3098, -0.9253,  ...,  2.3809,  1.1504, -1.6709]]],
       dtype=torch.float16), 'language_model.model.norm': tensor([[[-0.7412, -0.1621, -0.4680,  ...,  1.1465,  0.5894, -0.7500]]],
       dtype=torch.float16)}}